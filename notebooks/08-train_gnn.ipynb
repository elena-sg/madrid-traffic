{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bened\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220512_010356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from graph_traffic.dataloading import graph_dataset, npzDataset\n",
    "from graph_traffic.dcrnn import DiffConv\n",
    "from graph_traffic.config import project_path\n",
    "from graph_traffic.model import GraphRNN\n",
    "from graph_traffic.train import train, eval, predict\n",
    "from graph_traffic.utils import NormalizationLayer, masked_mae_loss\n",
    "from graph_traffic.get_data import get_data, plot_graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "training_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(training_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Define training parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    n_points=None,\n",
    "    batch_size=64,\n",
    "    diffsteps=2,\n",
    "    decay_steps=2000,\n",
    "    lr=0.01,\n",
    "    minimum_lr=2e-6,\n",
    "    epochs=100,\n",
    "    max_grad_norm=5.0,\n",
    "    num_workers=0,\n",
    "    model=\"dcrnn\",\n",
    "    gpu=-1,\n",
    "    num_heads=2, # relevant for model=\"gaan\"\n",
    "    out_feats=1*64,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "n_points = args[\"n_points\"]\n",
    "batch_size = args[\"batch_size\"]\n",
    "diffsteps = args[\"diffsteps\"]\n",
    "decay_steps = args[\"decay_steps\"]\n",
    "lr = args[\"lr\"]\n",
    "minimum_lr = args[\"minimum_lr\"]\n",
    "epochs = args[\"epochs\"]\n",
    "max_grad_norm = args[\"max_grad_norm\"]\n",
    "num_workers = args[\"num_workers\"]\n",
    "model = args[\"model\"]\n",
    "gpu = args[\"gpu\"]\n",
    "num_heads = args[\"num_heads\"]\n",
    "out_feats = args[\"out_feats\"]\n",
    "num_layers = args[\"num_layers\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if gpu == -1:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(gpu))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_dict = dict(\n",
    "    ids_list=[1001, 1002, 1003],#[3954, 3973],#, 3976, 3977, 3978],\n",
    "\n",
    "    seq_len=12,\n",
    "    with_graph=True,\n",
    "    from_date=\"2019-01-01\",\n",
    "    to_date=\"2019-01-31\",\n",
    "    dataset_name=\"small\",\n",
    "    target=\"vmed\",  # 1\n",
    "    interactions=None\n",
    ")\n",
    "\n",
    "meteo_dict = dict(\n",
    "    rain=\"drop\",  # 1\n",
    "    wind=\"drop\",\n",
    "    temperature=\"drop\",  # 0\n",
    "    humidity=\"drop\",  # 1\n",
    "    pressure=\"drop\",  # 0\n",
    "    radiation=\"drop\"  # 0\n",
    ")\n",
    "\n",
    "temporal_dict = dict(\n",
    "    season=\"drop\",\n",
    "    month=\"drop\",\n",
    "    day_of_month=\"drop\",\n",
    "    hour=\"drop\",\n",
    "    bank_holiday=\"drop\",\n",
    "    working_day=\"drop\",\n",
    "    school_holiday=\"drop\",\n",
    "    minute=\"drop\"\n",
    ")\n",
    "\n",
    "ids_list = data_dict[\"ids_list\"]\n",
    "rain = meteo_dict[\"rain\"]\n",
    "wind = meteo_dict[\"wind\"]\n",
    "season = temporal_dict[\"season\"]\n",
    "month = temporal_dict[\"month\"]\n",
    "day_of_month = temporal_dict[\"day_of_month\"]\n",
    "hour = temporal_dict[\"hour\"]\n",
    "interactions = data_dict[\"interactions\"]\n",
    "seq_len = data_dict[\"seq_len\"]\n",
    "with_graph = data_dict[\"with_graph\"]\n",
    "from_date = data_dict[\"from_date\"]\n",
    "to_date = data_dict[\"to_date\"]\n",
    "dataset_name = data_dict[\"dataset_name\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save variables in text file for the records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "training_folder = f\"{project_path}/training_history/{training_time}\"\n",
    "os.mkdir(training_folder)\n",
    "with open(f\"{training_folder}/learning_args.pkl\", \"wb\") as f:\n",
    "    pickle.dump(args, f)\n",
    "with open(f\"{training_folder}/data_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "with open(f\"{training_folder}/meteo_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(meteo_dict, f)\n",
    "with open(f\"{training_folder}/temporal_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(temporal_dict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "x, y, g = get_data(data_dict, meteo_dict, temporal_dict)\n",
    "plot_graph(g, ids_list, save_dir=training_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'weight': tensor([0.0110, 0.0150, 0.9938, 0.0108, 0.9772, 0.9946], dtype=torch.float64)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "g = graph_dataset(dataset_name)\n",
    "train_data = npzDataset(dataset_name, \"train\", n_points)\n",
    "test_data = npzDataset(dataset_name, \"test\", n_points)\n",
    "valid_data = npzDataset(dataset_name, \"valid\", n_points)\n",
    "\n",
    "seq_len = train_data.x.shape[1]\n",
    "in_feats = train_data.x.shape[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "((1246, 12, 3, 1), (1246, 12, 3, 1))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.x.shape, train_data.y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "((416, 12, 3, 1), (416, 12, 3, 1))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.x.shape, valid_data.y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((416, 12, 3, 1), (416, 12, 3, 1))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.x.shape, test_data.y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "valid_loader = DataLoader(\n",
    "    valid_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "normalizer = NormalizationLayer(train_data.min, train_data.max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if model == \"dcrnn\":\n",
    "    batch_g = dgl.batch([g] * batch_size).to(device)\n",
    "    out_gs, in_gs = DiffConv.attach_graph(batch_g, diffsteps)\n",
    "    net = partial(DiffConv, k=diffsteps, in_graph_list=in_gs, out_graph_list=out_gs)\n",
    "elif model == 'gaan':\n",
    "    print(\"not available\")\n",
    "\n",
    "dcrnn = GraphRNN(in_feats=in_feats,\n",
    "                 out_feats=out_feats,\n",
    "                 seq_len=seq_len,\n",
    "                 num_layers=num_layers,\n",
    "                 net=net,\n",
    "                 decay_steps=decay_steps).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define learning parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dcrnn.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "loss_fn = masked_mae_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DespuÃ©s de hacer el cambio sigmoid -> tanh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bened\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\torch\\autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 6.243885538474599 Valid Loss: 6.456023456321822 Test Loss: 5.614185360181634\n",
      "Epoch: 1 Train Loss: 4.461135323383045 Valid Loss: 5.9736980980350864 Test Loss: 4.113220175046369\n",
      "Epoch: 2 Train Loss: 4.465982259526767 Valid Loss: 4.939263682753321 Test Loss: 3.8305413879983212\n",
      "Epoch: 3 Train Loss: 4.937854397456348 Valid Loss: 5.324178788397048 Test Loss: 4.260857690596039\n",
      "Epoch: 4 Train Loss: 4.441503545895494 Valid Loss: 4.969624327525261 Test Loss: 3.998743617246309\n",
      "Epoch: 5 Train Loss: 4.487436960809012 Valid Loss: 5.061992068612386 Test Loss: 3.8735377938867948\n",
      "Batch:  6\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m test_losses \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdcrnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_grad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminimum_lr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(dcrnn, g, train_loader, normalizer, loss_fn, device, batch_size)\n\u001B[0;32m      7\u001B[0m     valid_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(dcrnn, g, valid_loader, normalizer, loss_fn, device, batch_size)\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\train.py:57\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, graph, dataloader, optimizer, scheduler, normalizer, loss_fn, device, batch_size, max_grad_norm, minimum_lr)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (x, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[0;32m     56\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 57\u001B[0m     y, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(y_pred, y)\n\u001B[0;32m     59\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\train.py:44\u001B[0m, in \u001B[0;36mpredict\u001B[1;34m(x, y, batch_size, graph, model, device, normalizer)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(x, y, batch_size, graph, model, device, normalizer):\n\u001B[0;32m     43\u001B[0m     x, y, x_norm, y_norm, batch_graph \u001B[38;5;241m=\u001B[39m prepare_data(x, y, batch_size, graph, normalizer, device)\n\u001B[1;32m---> 44\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_cnt\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m     output \u001B[38;5;241m=\u001B[39m output[:, :, [\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;66;03m# Denormalization for loss compute\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\model.py:220\u001B[0m, in \u001B[0;36mGraphRNN.forward\u001B[1;34m(self, g, inputs, teacher_states, batch_cnt, device)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, g, inputs, teacher_states, batch_cnt, device):\n\u001B[0;32m    219\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode(g, inputs, device)\n\u001B[1;32m--> 220\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteacher_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_cnt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\model.py:210\u001B[0m, in \u001B[0;36mGraphRNN.decode\u001B[1;34m(self, g, teacher_states, hidden_states, batch_cnt, device)\u001B[0m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseq_len):\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_thresh(batch_cnt) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[1;32m--> 210\u001B[0m         inputs, hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m            \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteacher_states\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    213\u001B[0m         inputs, hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(g, inputs, hidden_states)\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\model.py:136\u001B[0m, in \u001B[0;36mStackedDecoder.forward\u001B[1;34m(self, g, x, hidden_states)\u001B[0m\n\u001B[0;32m    134\u001B[0m hiddens \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers):\n\u001B[1;32m--> 136\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m     hiddens\u001B[38;5;241m.\u001B[39mappend(x)\n\u001B[0;32m    138\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_layer(x)\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\model.py:38\u001B[0m, in \u001B[0;36mGraphGRUCell.forward\u001B[1;34m(self, g, x, h)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, g, x, h):\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;66;03m# reset gate: how much of the past information to forget\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m     r \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mr_net\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mr_bias)\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# update gate: how much of the past information needs to be passed along to the future\u001B[39;00m\n\u001B[0;32m     41\u001B[0m     u \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mu_net(\n\u001B[0;32m     42\u001B[0m         g, torch\u001B[38;5;241m.\u001B[39mcat([x, h], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mu_bias)\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\graph_traffic\\graph_traffic\\dcrnn.py:102\u001B[0m, in \u001B[0;36mDiffConv.forward\u001B[1;34m(self, g, x)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m g\u001B[38;5;241m.\u001B[39mlocal_scope():\n\u001B[0;32m    101\u001B[0m     g\u001B[38;5;241m.\u001B[39mndata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproject_fcs[i](x)\n\u001B[1;32m--> 102\u001B[0m     \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mu_mul_e\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43me\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mfn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43me\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfeat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    104\u001B[0m     feat_list\u001B[38;5;241m.\u001B[39mappend(g\u001B[38;5;241m.\u001B[39mndata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeat\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;66;03m# Each feat has shape [N,q_feats]\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\dgl\\heterograph.py:4894\u001B[0m, in \u001B[0;36mDGLHeteroGraph.update_all\u001B[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001B[0m\n\u001B[0;32m   4892\u001B[0m etype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcanonical_etypes[etid]\n\u001B[0;32m   4893\u001B[0m _, dtid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph\u001B[38;5;241m.\u001B[39mmetagraph\u001B[38;5;241m.\u001B[39mfind_edge(etid)\n\u001B[1;32m-> 4894\u001B[0m g \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m etype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43metype\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   4895\u001B[0m ndata \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mmessage_passing(g, message_func, reduce_func, apply_node_func)\n\u001B[0;32m   4896\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m core\u001B[38;5;241m.\u001B[39mis_builtin(reduce_func) \u001B[38;5;129;01mand\u001B[39;00m reduce_func\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m ndata:\n\u001B[0;32m   4897\u001B[0m     \u001B[38;5;66;03m# Replace infinity with zero for isolated nodes\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\dgl\\heterograph.py:2248\u001B[0m, in \u001B[0;36mDGLHeteroGraph.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2246\u001B[0m etid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_etype_id((srctype, etype, dsttype))\n\u001B[0;32m   2247\u001B[0m dtid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_ntype_id_from_dst(dsttype)\n\u001B[1;32m-> 2248\u001B[0m new_g \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_relation_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43metid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stid \u001B[38;5;241m==\u001B[39m dtid:\n\u001B[0;32m   2251\u001B[0m     new_ntypes \u001B[38;5;241m=\u001B[39m [srctype]\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\dgl\\heterograph_index.py:95\u001B[0m, in \u001B[0;36mHeteroGraphIndex.get_relation_graph\u001B[1;34m(self, etype)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_relation_graph\u001B[39m(\u001B[38;5;28mself\u001B[39m, etype):\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;124;03m\"\"\"Get the unitgraph graph of the given edge/relation type.\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \n\u001B[0;32m     85\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;124;03m        The unitgraph graph.\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_CAPI_DGLHeteroGetRelationGraph\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\madrid-traffic\\env\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py:188\u001B[0m, in \u001B[0;36mFunctionBase.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    186\u001B[0m ret_val \u001B[38;5;241m=\u001B[39m DGLValue()\n\u001B[0;32m    187\u001B[0m ret_tcode \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mc_int()\n\u001B[1;32m--> 188\u001B[0m check_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDGLFuncCall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtcodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_args\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret_tcode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    191\u001B[0m _ \u001B[38;5;241m=\u001B[39m temp_args\n\u001B[0;32m    192\u001B[0m _ \u001B[38;5;241m=\u001B[39m args\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "test_losses = []\n",
    "for e in range(epochs):\n",
    "    train(dcrnn, g, train_loader, optimizer, scheduler, normalizer, loss_fn, device, batch_size, max_grad_norm, minimum_lr)\n",
    "    train_loss = eval(dcrnn, g, train_loader, normalizer, loss_fn, device, batch_size)\n",
    "    valid_loss = eval(dcrnn, g, valid_loader, normalizer, loss_fn, device, batch_size)\n",
    "    test_loss = eval(dcrnn, g, test_loader, normalizer, loss_fn, device, batch_size)\n",
    "    print(f\"Epoch: {e} Train Loss: {train_loss} Valid Loss: {valid_loss} Test Loss: {test_loss}\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    ax.plot(train_losses, label=\"train\")\n",
    "    ax.plot(valid_losses, label=\"validation\")\n",
    "    ax.plot(test_losses, label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{training_folder}/learning_curve.svg\")\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "os.mkdir(f\"{training_folder}/losses\")\n",
    "with open(f\"{training_folder}/losses/train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_losses, f)\n",
    "with open(f\"{training_folder}/losses/valid.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valid_losses, f)\n",
    "with open(f\"{training_folder}/losses/test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_losses, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "torch.save(dcrnn.state_dict(), f\"{training_folder}/model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Try model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "matplotlib.use(\"TkAgg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(train_loader):\n",
    "    #x, y, x_norm, y_norm, batch_graph = prepare_data(g.to(device), x, y, normalizer, args.batch_size, device)\n",
    "    #y_pred = predict(dcrnn, batch_graph, x_norm, y_norm, normalizer, device, i)\n",
    "    dcrnn.eval()\n",
    "    y, y_pred = predict(x, y, batch_size, g.to(device), dcrnn, device, normalizer)\n",
    "    break\n",
    "\n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.set_title(f\"de {(y[:, i, 1]*24).min().numpy()} a  {(y[:, i, 1]*24).max().numpy()}, sensor{i%5+1}\")\n",
    "    ax.plot(y[:, i, 0].detach().numpy(), label=\"real\")\n",
    "    ax.plot(y_pred[:, i, 0].detach().numpy(), label=\"pred\")\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mscatter(y\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mravel(), y_pred\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mravel())\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(y.detach().numpy().ravel(), y_pred.detach().numpy().ravel())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(valid_loader):\n",
    "    #x, y, x_norm, y_norm, batch_graph = prepare_data(g.to(device), x, y, normalizer, args.batch_size, device)\n",
    "    #y_pred = predict(dcrnn, batch_graph, x_norm, y_norm, normalizer, device, i)\n",
    "    dcrnn.eval()\n",
    "    y, y_pred = predict(x, y, batch_size, g.to(device), dcrnn, device, normalizer)\n",
    "    break\n",
    "plt.scatter(y.detach().numpy().ravel(), y_pred.detach().numpy().ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(test_loader):\n",
    "    #x, y, x_norm, y_norm, batch_graph = prepare_data(g.to(device), x, y, normalizer, args.batch_size, device)\n",
    "    #y_pred = predict(dcrnn, batch_graph, x_norm, y_norm, normalizer, device, i)\n",
    "    dcrnn.eval()\n",
    "    y, y_pred = predict(x, y, batch_size, g.to(device), dcrnn, device, normalizer)\n",
    "    break\n",
    "plt.scatter(y.detach().numpy().ravel(), y_pred.detach().numpy().ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}